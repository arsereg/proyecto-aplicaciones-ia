{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bff4dfa-8b3c-4407-8d86-ed398af69e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar otras dependencias para ayudarnos\n",
    "#!pip install tensorflow\n",
    "#!pip install -q \"tqdm>=4.36.1\"\n",
    "# !pip install tensorflow-addons==0.22.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ddee068-ea03-434b-b08f-5770b5f2c5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-23 16:46:33.569143: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-23 16:46:33.591886: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-23 16:46:33.915170: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.1\n"
     ]
    }
   ],
   "source": [
    "# importar librer√≠as\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tqdm\n",
    "# import tensorflow_addons as tfa\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d228b85e-bdbc-440b-b542-926f58cdff39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pelvic_incidence</th>\n",
       "      <th>pelvic_tilt numeric</th>\n",
       "      <th>lumbar_lordosis_angle</th>\n",
       "      <th>sacral_slope</th>\n",
       "      <th>pelvic_radius</th>\n",
       "      <th>degree_spondylolisthesis</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>54.124920</td>\n",
       "      <td>26.650489</td>\n",
       "      <td>35.329747</td>\n",
       "      <td>27.474432</td>\n",
       "      <td>121.447011</td>\n",
       "      <td>1.571205</td>\n",
       "      <td>Abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>52.204693</td>\n",
       "      <td>17.212673</td>\n",
       "      <td>78.094969</td>\n",
       "      <td>34.992020</td>\n",
       "      <td>136.972517</td>\n",
       "      <td>54.939134</td>\n",
       "      <td>Abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>40.349296</td>\n",
       "      <td>10.194748</td>\n",
       "      <td>37.967747</td>\n",
       "      <td>30.154548</td>\n",
       "      <td>128.009927</td>\n",
       "      <td>0.458901</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>70.952728</td>\n",
       "      <td>20.159931</td>\n",
       "      <td>62.859109</td>\n",
       "      <td>50.792797</td>\n",
       "      <td>116.177932</td>\n",
       "      <td>32.522331</td>\n",
       "      <td>Abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>63.404481</td>\n",
       "      <td>14.115327</td>\n",
       "      <td>48.136806</td>\n",
       "      <td>49.289153</td>\n",
       "      <td>111.916008</td>\n",
       "      <td>31.784495</td>\n",
       "      <td>Abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>31.232387</td>\n",
       "      <td>17.715819</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>13.516568</td>\n",
       "      <td>120.055399</td>\n",
       "      <td>0.499751</td>\n",
       "      <td>Abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>32.090987</td>\n",
       "      <td>6.989378</td>\n",
       "      <td>35.998198</td>\n",
       "      <td>25.101609</td>\n",
       "      <td>132.264735</td>\n",
       "      <td>6.413428</td>\n",
       "      <td>Abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>49.828135</td>\n",
       "      <td>16.736435</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>33.091700</td>\n",
       "      <td>121.435558</td>\n",
       "      <td>1.913307</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>74.433593</td>\n",
       "      <td>41.557331</td>\n",
       "      <td>27.700000</td>\n",
       "      <td>32.876262</td>\n",
       "      <td>107.949304</td>\n",
       "      <td>5.000089</td>\n",
       "      <td>Abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>89.504947</td>\n",
       "      <td>48.903653</td>\n",
       "      <td>72.003423</td>\n",
       "      <td>40.601295</td>\n",
       "      <td>134.634291</td>\n",
       "      <td>118.353370</td>\n",
       "      <td>Abnormal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pelvic_incidence  pelvic_tilt numeric  lumbar_lordosis_angle  \\\n",
       "25          54.124920            26.650489              35.329747   \n",
       "134         52.204693            17.212673              78.094969   \n",
       "258         40.349296            10.194748              37.967747   \n",
       "91          70.952728            20.159931              62.859109   \n",
       "152         63.404481            14.115327              48.136806   \n",
       "11          31.232387            17.715819              15.500000   \n",
       "36          32.090987             6.989378              35.998198   \n",
       "247         49.828135            16.736435              28.000000   \n",
       "51          74.433593            41.557331              27.700000   \n",
       "141         89.504947            48.903653              72.003423   \n",
       "\n",
       "     sacral_slope  pelvic_radius  degree_spondylolisthesis     class  \n",
       "25      27.474432     121.447011                  1.571205  Abnormal  \n",
       "134     34.992020     136.972517                 54.939134  Abnormal  \n",
       "258     30.154548     128.009927                  0.458901    Normal  \n",
       "91      50.792797     116.177932                 32.522331  Abnormal  \n",
       "152     49.289153     111.916008                 31.784495  Abnormal  \n",
       "11      13.516568     120.055399                  0.499751  Abnormal  \n",
       "36      25.101609     132.264735                  6.413428  Abnormal  \n",
       "247     33.091700     121.435558                  1.913307    Normal  \n",
       "51      32.876262     107.949304                  5.000089  Abnormal  \n",
       "141     40.601295     134.634291                118.353370  Abnormal  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos la data\n",
    "data = pd.read_csv(\"data.csv\", header=0)\n",
    "# Hacemos un shuffle de los rows\n",
    "data = data.sample(frac = 1)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c4bf8c9-4110-4c3a-ba39-1128fce78db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pelvic_incidence</th>\n",
       "      <th>pelvic_tilt numeric</th>\n",
       "      <th>lumbar_lordosis_angle</th>\n",
       "      <th>sacral_slope</th>\n",
       "      <th>pelvic_radius</th>\n",
       "      <th>degree_spondylolisthesis</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>54.124920</td>\n",
       "      <td>26.650489</td>\n",
       "      <td>35.329747</td>\n",
       "      <td>27.474432</td>\n",
       "      <td>121.447011</td>\n",
       "      <td>1.571205</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>52.204693</td>\n",
       "      <td>17.212673</td>\n",
       "      <td>78.094969</td>\n",
       "      <td>34.992020</td>\n",
       "      <td>136.972517</td>\n",
       "      <td>54.939134</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>40.349296</td>\n",
       "      <td>10.194748</td>\n",
       "      <td>37.967747</td>\n",
       "      <td>30.154548</td>\n",
       "      <td>128.009927</td>\n",
       "      <td>0.458901</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>70.952728</td>\n",
       "      <td>20.159931</td>\n",
       "      <td>62.859109</td>\n",
       "      <td>50.792797</td>\n",
       "      <td>116.177932</td>\n",
       "      <td>32.522331</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>63.404481</td>\n",
       "      <td>14.115327</td>\n",
       "      <td>48.136806</td>\n",
       "      <td>49.289153</td>\n",
       "      <td>111.916008</td>\n",
       "      <td>31.784495</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>31.232387</td>\n",
       "      <td>17.715819</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>13.516568</td>\n",
       "      <td>120.055399</td>\n",
       "      <td>0.499751</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>32.090987</td>\n",
       "      <td>6.989378</td>\n",
       "      <td>35.998198</td>\n",
       "      <td>25.101609</td>\n",
       "      <td>132.264735</td>\n",
       "      <td>6.413428</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>49.828135</td>\n",
       "      <td>16.736435</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>33.091700</td>\n",
       "      <td>121.435558</td>\n",
       "      <td>1.913307</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>74.433593</td>\n",
       "      <td>41.557331</td>\n",
       "      <td>27.700000</td>\n",
       "      <td>32.876262</td>\n",
       "      <td>107.949304</td>\n",
       "      <td>5.000089</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>89.504947</td>\n",
       "      <td>48.903653</td>\n",
       "      <td>72.003423</td>\n",
       "      <td>40.601295</td>\n",
       "      <td>134.634291</td>\n",
       "      <td>118.353370</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pelvic_incidence  pelvic_tilt numeric  lumbar_lordosis_angle  \\\n",
       "25          54.124920            26.650489              35.329747   \n",
       "134         52.204693            17.212673              78.094969   \n",
       "258         40.349296            10.194748              37.967747   \n",
       "91          70.952728            20.159931              62.859109   \n",
       "152         63.404481            14.115327              48.136806   \n",
       "11          31.232387            17.715819              15.500000   \n",
       "36          32.090987             6.989378              35.998198   \n",
       "247         49.828135            16.736435              28.000000   \n",
       "51          74.433593            41.557331              27.700000   \n",
       "141         89.504947            48.903653              72.003423   \n",
       "\n",
       "     sacral_slope  pelvic_radius  degree_spondylolisthesis  class  \n",
       "25      27.474432     121.447011                  1.571205      0  \n",
       "134     34.992020     136.972517                 54.939134      0  \n",
       "258     30.154548     128.009927                  0.458901      1  \n",
       "91      50.792797     116.177932                 32.522331      0  \n",
       "152     49.289153     111.916008                 31.784495      0  \n",
       "11      13.516568     120.055399                  0.499751      0  \n",
       "36      25.101609     132.264735                  6.413428      0  \n",
       "247     33.091700     121.435558                  1.913307      1  \n",
       "51      32.876262     107.949304                  5.000089      0  \n",
       "141     40.601295     134.634291                118.353370      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creamos una lista de las posibles clases y su representaci√≥n inversa\n",
    "class_names = {\n",
    "    \"Abnormal\": 0,\n",
    "    \"Normal\": 1\n",
    "}\n",
    "reversed_class_names = {v: k for k, v in class_names.items()}\n",
    "data['class'] = data['class'].map(class_names)\n",
    "data.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6aa83a5b-b578-45fb-ba96-1ada69a9e026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207    0\n",
      "23     0\n",
      "106    0\n",
      "174    0\n",
      "140    0\n",
      "254    1\n",
      "122    0\n",
      "115    0\n",
      "30     0\n",
      "119    0\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Definimos los porcentajes de entrenamiento:\n",
    "\n",
    "dataset_percent_for_training = 0.8\n",
    "dataset_percent_for_testing = 0.2\n",
    "data_count = len(data)\n",
    "training_count = int((data_count * dataset_percent_for_training))\n",
    "testing_count = int(data_count * dataset_percent_for_testing)\n",
    "\n",
    "# Creamos los sets de entrenamiento y de pruebas\n",
    "training_data = data.iloc[:, :5][:training_count]\n",
    "training_labels = data.iloc[:, 6][:training_count]\n",
    "\n",
    "testing_data = data.iloc[:, :5][training_count:training_count + testing_count]\n",
    "testing_labels = data.iloc[:, 6][training_count:training_count + testing_count]\n",
    "print(testing_labels.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb42a60-cbbf-4e89-a11c-0b5638055634",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-23 16:46:34.506153: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-23 16:46:34.526037: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-23 16:46:34.527563: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-23 16:46:34.531072: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-23 16:46:34.532603: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-23 16:46:34.534440: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-23 16:46:34.636114: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-23 16:46:34.637340: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-23 16:46:34.638487: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-23 16:46:34.639639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21394 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1713912395.067134  655857 service.cc:145] XLA service 0x793a200063d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1713912395.067150  655857 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2024-04-23 16:46:35.074723: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-04-23 16:46:35.122240: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "I0000 00:00:1713912395.378251  655857 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - 133ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.3387 - loss: 0.6904\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.3710 - loss: 0.6931\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function TensorFlowTrainer.make_test_function.<locals>.one_step_on_iterator at 0x793b7975bd00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6613 - loss: 1.6355\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function TensorFlowTrainer.make_test_function.<locals>.one_step_on_iterator at 0x793ba0151c60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6774 - loss: 0.6288\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6290 - loss: 0.6931\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6613 - loss: 0.9350\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6774 - loss: 0.6243\n",
      "2/2 - 0s - 91ms/step - accuracy: 0.6613 - loss: 0.9299\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6774 - loss: 0.6964\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.3387 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 91ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 88ms/step - accuracy: 0.6613 - loss: 0.8958\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6452 - loss: 0.8844\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6613 - loss: 0.6305\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 88ms/step - accuracy: 0.6613 - loss: 0.6337\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6774 - loss: 0.6288\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6774 - loss: 0.6484\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.7419 - loss: 0.5145\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.4194 - loss: 0.6820\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.6613 - loss: 0.9285\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.3871 - loss: 0.6516\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.3387 - loss: 0.6877\n",
      "2/2 - 0s - 89ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.7097 - loss: 0.5355\n",
      "2/2 - 0s - 87ms/step - accuracy: 0.4194 - loss: 0.6931\n",
      "2/2 - 0s - 87ms/step - accuracy: 0.3226 - loss: 0.8896\n",
      "2/2 - 0s - 87ms/step - accuracy: 0.6774 - loss: 0.9144\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.6774 - loss: 0.6756\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.5968 - loss: 0.6931\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.6613 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 87ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 176ms/step - accuracy: 0.6774 - loss: 0.6288\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.3548 - loss: 0.6764\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6774 - loss: 0.6288\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.3226 - loss: 1.3534\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.3387 - loss: 0.6820\n",
      "2/2 - 0s - 87ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.6774 - loss: 0.6288\n",
      "2/2 - 0s - 89ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6452 - loss: 1.1393\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.7625\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6774 - loss: 0.6708\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6613 - loss: 0.6378\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.3710 - loss: 0.6820\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.3387 - loss: 0.6975\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.3710 - loss: 0.7480\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6613 - loss: 0.8661\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6613 - loss: 0.9146\n",
      "2/2 - 0s - 92ms/step - accuracy: 0.6774 - loss: 0.6288\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6288\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.5000 - loss: 0.7641\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.6774 - loss: 0.6288\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.7097 - loss: 0.8681\n",
      "2/2 - 0s - 87ms/step - accuracy: 0.6613 - loss: 0.6336\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.6452 - loss: 0.6362\n",
      "2/2 - 0s - 90ms/step - accuracy: 0.6774 - loss: 0.6225\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.3871 - loss: 0.8807\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6290 - loss: 0.6931\n",
      "2/2 - 0s - 87ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.5968 - loss: 0.6931\n",
      "2/2 - 0s - 91ms/step - accuracy: 0.2903 - loss: 0.9299\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.6774 - loss: 0.5313\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.7419 - loss: 0.6087\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6774 - loss: 1.4574\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6290 - loss: 0.6464\n",
      "2/2 - 0s - 87ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 87ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.5323 - loss: 0.6929\n",
      "2/2 - 0s - 89ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6613 - loss: 0.6931\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.3226 - loss: 1.1589\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6774 - loss: 0.6288\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6820\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 87ms/step - accuracy: 0.6774 - loss: 0.6903\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6774 - loss: 0.6288\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 90ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.3226 - loss: 1.0928\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.6774 - loss: 0.6293\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.6774 - loss: 0.6288\n",
      "2/2 - 0s - 87ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.3387 - loss: 0.6820\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 87ms/step - accuracy: 0.6774 - loss: 0.8724\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.6613 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6935 - loss: 0.8799\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6452 - loss: 0.6985\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6613 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6484\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 91ms/step - accuracy: 0.6774 - loss: 0.6356\n",
      "2/2 - 0s - 89ms/step - accuracy: 0.6774 - loss: 0.6288\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.7903 - loss: 0.5188\n",
      "2/2 - 0s - 87ms/step - accuracy: 0.6774 - loss: 0.6288\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.8600\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6452 - loss: 0.8474\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6820\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.9448\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.6774 - loss: 0.6287\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.4032 - loss: 0.6931\n",
      "2/2 - 0s - 87ms/step - accuracy: 0.6774 - loss: 0.7875\n",
      "2/2 - 0s - 87ms/step - accuracy: 0.6613 - loss: 0.6358\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.5963\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6708\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.4516 - loss: 0.6931\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6774 - loss: 0.6533\n",
      "2/2 - 0s - 87ms/step - accuracy: 0.3226 - loss: 0.8499\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.9834\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.3387 - loss: 0.6820\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.5806 - loss: 0.6962\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6445\n",
      "2/2 - 0s - 89ms/step - accuracy: 0.6774 - loss: 0.6029\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.7419 - loss: 0.6552\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6288\n",
      "2/2 - 0s - 89ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.3226 - loss: 0.9226\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.3387 - loss: 0.6820\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6288\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 87ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6288\n",
      "2/2 - 0s - 88ms/step - accuracy: 0.3871 - loss: 0.8757\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.3548 - loss: 0.6708\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.6774 - loss: 0.6820\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.3710 - loss: 7.9978\n",
      "2/2 - 0s - 90ms/step - accuracy: 0.6774 - loss: 0.8213\n",
      "2/2 - 0s - 87ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.3710 - loss: 0.6597\n",
      "2/2 - 0s - 88ms/step - accuracy: 0.6452 - loss: 1.1415\n",
      "2/2 - 0s - 87ms/step - accuracy: 0.7581 - loss: 0.5343\n",
      "2/2 - 0s - 91ms/step - accuracy: 0.6774 - loss: 0.6708\n",
      "2/2 - 0s - 88ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6613 - loss: 0.9280\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.7097 - loss: 0.6709\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.5806 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 87ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 87ms/step - accuracy: 0.5484 - loss: 1.2186\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 90ms/step - accuracy: 0.6774 - loss: 0.8545\n",
      "2/2 - 0s - 88ms/step - accuracy: 0.5161 - loss: 0.6239\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6613 - loss: 0.6931\n",
      "2/2 - 0s - 88ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6161\n",
      "2/2 - 0s - 89ms/step - accuracy: 0.6452 - loss: 1.0972\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.6774 - loss: 4.6362\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.3871 - loss: 0.6739\n",
      "2/2 - 0s - 88ms/step - accuracy: 0.3548 - loss: 0.6708\n",
      "2/2 - 0s - 88ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6129 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6372\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.3226 - loss: 0.9131\n",
      "2/2 - 0s - 87ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 89ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6613 - loss: 0.8110\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 88ms/step - accuracy: 0.6774 - loss: 0.6484\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.3710 - loss: 0.8600\n",
      "2/2 - 0s - 90ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.7097 - loss: 0.5470\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6613 - loss: 0.9267\n",
      "2/2 - 0s - 88ms/step - accuracy: 0.6613 - loss: 0.8972\n",
      "2/2 - 0s - 90ms/step - accuracy: 0.6774 - loss: 0.6280\n",
      "2/2 - 0s - 88ms/step - accuracy: 0.6129 - loss: 0.7501\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6291\n",
      "2/2 - 0s - 88ms/step - accuracy: 0.3226 - loss: 0.9171\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6129 - loss: 0.6708\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6288\n",
      "2/2 - 0s - 90ms/step - accuracy: 0.6774 - loss: 0.6780\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 91ms/step - accuracy: 0.3387 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.5968 - loss: 0.7891\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6290 - loss: 0.5731\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6224\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.6774 - loss: 0.5947\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6774 - loss: 0.6288\n",
      "2/2 - 0s - 90ms/step - accuracy: 0.3226 - loss: 0.7009\n",
      "2/2 - 0s - 87ms/step - accuracy: 0.6290 - loss: 0.6434\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 87ms/step - accuracy: 0.6613 - loss: 0.6952\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.6452 - loss: 0.9229\n",
      "2/2 - 0s - 87ms/step - accuracy: 0.6774 - loss: 1.0509\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.4194 - loss: 0.6372\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.6452 - loss: 0.6112\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6288\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.4516 - loss: 0.6931\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6189\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6484\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 96ms/step - accuracy: 0.6774 - loss: 0.6820\n",
      "2/2 - 0s - 89ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6774 - loss: 0.6288\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.4677 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 91ms/step - accuracy: 0.6774 - loss: 0.6330\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6288\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.3548 - loss: 0.6708\n",
      "2/2 - 0s - 92ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.3548 - loss: 0.6820\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.4677 - loss: 0.6149\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.5806 - loss: 0.6963\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6365\n",
      "2/2 - 0s - 88ms/step - accuracy: 0.7097 - loss: 0.8847\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6774 - loss: 0.6292\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6452 - loss: 0.6931\n",
      "2/2 - 0s - 89ms/step - accuracy: 0.6290 - loss: 0.5495\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.6935 - loss: 0.6097\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.3387 - loss: 0.6882\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.6774 - loss: 0.6288\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.3710 - loss: 0.9026\n",
      "2/2 - 0s - 90ms/step - accuracy: 0.6774 - loss: 0.6269\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6290 - loss: 1.1116\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6839\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6774 - loss: 0.6288\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.3548 - loss: 0.6820\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6613 - loss: 0.8866\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6288\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.3548 - loss: 0.6708\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.6613 - loss: 0.9172\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.5968 - loss: 0.6994\n",
      "2/2 - 0s - 87ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 88ms/step - accuracy: 0.5484 - loss: 0.5976\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 89ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.4032 - loss: 0.6931\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.3871 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.7419 - loss: 0.8782\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.3387 - loss: 0.6820\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.7059\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 88ms/step - accuracy: 0.7419 - loss: 0.6495\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 88ms/step - accuracy: 0.6774 - loss: 0.6288\n",
      "2/2 - 0s - 89ms/step - accuracy: 0.6613 - loss: 0.6337\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 88ms/step - accuracy: 0.3387 - loss: 0.8850\n",
      "2/2 - 0s - 87ms/step - accuracy: 0.5806 - loss: 0.5771\n",
      "2/2 - 0s - 87ms/step - accuracy: 0.7097 - loss: 0.6708\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.3871 - loss: 0.8702\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6783\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6613 - loss: 0.8990\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 88ms/step - accuracy: 0.6613 - loss: 0.7942\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.3710 - loss: 0.6656\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6288\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.7419 - loss: 0.6931\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6774 - loss: 0.6288\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6288\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.3387 - loss: 0.6820\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 87ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6613 - loss: 0.6931\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.5968 - loss: 0.6803\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 87ms/step - accuracy: 0.6774 - loss: 0.6708\n",
      "2/2 - 0s - 91ms/step - accuracy: 0.6290 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6820\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6290 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.3548 - loss: 0.8715\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.6774 - loss: 0.6288\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.4839 - loss: 0.6561\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.2742 - loss: 0.6931\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.5323 - loss: 0.6931\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6774 - loss: 0.7528\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.6290 - loss: 0.6689\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6708\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6774 - loss: 0.6284\n",
      "2/2 - 0s - 88ms/step - accuracy: 0.6774 - loss: 0.6369\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.3387 - loss: 0.9293\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.5161 - loss: 0.6854\n",
      "2/2 - 0s - 90ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6288\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.6290 - loss: 0.6596\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.4032 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 87ms/step - accuracy: 0.6774 - loss: 0.6820\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.2581 - loss: 0.6931\n",
      "2/2 - 0s - 88ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 88ms/step - accuracy: 0.6774 - loss: 0.6288\n",
      "2/2 - 0s - 89ms/step - accuracy: 0.6129 - loss: 0.6395\n",
      "2/2 - 0s - 87ms/step - accuracy: 0.6613 - loss: 0.6931\n",
      "2/2 - 0s - 87ms/step - accuracy: 0.7581 - loss: 0.6820\n",
      "2/2 - 0s - 88ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 91ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 88ms/step - accuracy: 0.7097 - loss: 0.5377\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6613 - loss: 0.9139\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6774 - loss: 0.6288\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6708\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.3387 - loss: 0.9187\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6452 - loss: 0.6931\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6290 - loss: 1.0833\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6613 - loss: 0.9059\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 89ms/step - accuracy: 0.3387 - loss: 0.9118\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.3387 - loss: 0.6910\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.5968 - loss: 0.6931\n",
      "2/2 - 0s - 96ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 90ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 87ms/step - accuracy: 0.6613 - loss: 0.8387\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.3226 - loss: 1.1349\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6288\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 90ms/step - accuracy: 0.6613 - loss: 0.6425\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.5645 - loss: 0.6609\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.3226 - loss: 0.8551\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.6452 - loss: 0.6282\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 88ms/step - accuracy: 0.6774 - loss: 0.6708\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.6774 - loss: 0.6820\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6774 - loss: 0.6288\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 87ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6243\n",
      "2/2 - 0s - 88ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6708\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.7258 - loss: 0.9285\n",
      "2/2 - 0s - 88ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.6290 - loss: 0.6423\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 94ms/step - accuracy: 0.3387 - loss: 0.9065\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.6774 - loss: 0.6820\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6288\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.4194 - loss: 0.8736\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6774 - loss: 0.6225\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6313\n",
      "2/2 - 0s - 88ms/step - accuracy: 0.6774 - loss: 0.8182\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.4194 - loss: 0.6758\n",
      "2/2 - 0s - 89ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.3387 - loss: 0.6820\n",
      "2/2 - 0s - 97ms/step - accuracy: 0.3871 - loss: 0.6596\n",
      "2/2 - 0s - 90ms/step - accuracy: 0.3387 - loss: 0.6820\n",
      "2/2 - 0s - 89ms/step - accuracy: 0.6774 - loss: 0.6253\n",
      "2/2 - 0s - 88ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 89ms/step - accuracy: 0.6774 - loss: 0.6820\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6288\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6613 - loss: 0.8851\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6613 - loss: 0.6933\n",
      "2/2 - 0s - 89ms/step - accuracy: 0.7258 - loss: 0.8740\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 87ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 89ms/step - accuracy: 0.3387 - loss: 0.6820\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.4677 - loss: 0.8162\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6708\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.6290 - loss: 1.0771\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 89ms/step - accuracy: 0.4516 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.5000 - loss: 0.6931\n",
      "2/2 - 0s - 87ms/step - accuracy: 0.6774 - loss: 0.6288\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 87ms/step - accuracy: 0.3710 - loss: 0.6931\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6290 - loss: 0.6988\n",
      "2/2 - 0s - 87ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.3871 - loss: 0.6931\n",
      "2/2 - 0s - 87ms/step - accuracy: 0.6774 - loss: 0.6854\n",
      "2/2 - 0s - 88ms/step - accuracy: 0.6774 - loss: 0.6288\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 91ms/step - accuracy: 0.6774 - loss: 0.8390\n",
      "2/2 - 0s - 87ms/step - accuracy: 0.3226 - loss: 0.9072\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6935 - loss: 0.6799\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.3226 - loss: 0.9272\n",
      "2/2 - 0s - 88ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6774 - loss: 0.5959\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6774 - loss: 0.6443\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6037\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.3548 - loss: 0.6820\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.5806 - loss: 0.5805\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.6290 - loss: 1.0020\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.6774 - loss: 0.6266\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.3226 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.3387 - loss: 0.6886\n",
      "2/2 - 0s - 87ms/step - accuracy: 0.6774 - loss: 0.6507\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6290 - loss: 0.6931\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.6288\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6129 - loss: 1.4077\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6774 - loss: 0.6223\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.5000 - loss: 0.8614\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.5484 - loss: 1.1176\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6774 - loss: 0.6820\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.3548 - loss: 0.6899\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6935 - loss: 0.6179\n",
      "2/2 - 0s - 85ms/step - accuracy: 0.6774 - loss: 0.5393\n",
      "2/2 - 0s - 84ms/step - accuracy: 0.6774 - loss: 0.6931\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.7581 - loss: 0.7428\n",
      "2/2 - 0s - 88ms/step - accuracy: 0.6613 - loss: 0.6931\n",
      "2/2 - 0s - 86ms/step - accuracy: 0.6774 - loss: 0.6288\n"
     ]
    }
   ],
   "source": [
    "# Creamos una red neuronal. Esta red neuronal va a tener 6 neuronas iniciales,\n",
    "# para poder ser excitadas por las se√±ales de las columnas en la data.\n",
    "# Tendr√° una sola capa ya que las 6 neuronas tienen un valor \"relevante\" para el final.\n",
    "# Habr√° una sola neurona final que clasifique el resultado como Normal (1) o Anormal (0)\n",
    "test_acc = 0\n",
    "while test_acc < 0.9:\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(6, activation='softmax'),\n",
    "        keras.layers.Dense(2)\n",
    "    ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(\n",
    "        learning_rate=0.0007\n",
    "    )\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "                    metrics=['accuracy'])\n",
    "    #Definimos la cantidad de epocs de entrenamiento.\n",
    "    epochs = 150\n",
    "\n",
    "\n",
    "    #Comenzamos el entrenamiento\n",
    "    model.fit(training_data, training_labels, epochs=epochs, verbose=0)                         \n",
    "    test_loss, test_acc = model.evaluate(testing_data, testing_labels, verbose=2)\n",
    "for x in range(10):\n",
    "    !say \"Alert!\"\n",
    "    message = f\"Created a model with {test_acc * 100} percent accuracy\"\n",
    "    !say {message}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58797f9e-bae9-45ea-b49a-24e8122849fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluemos el modelo\n",
    "print('\\nTest accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8064d66c-0be7-49e6-9fe6-c9aa7b10d2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardemos el modelo\n",
    "\n",
    "model_path = 'models/trained_model-09.keras'\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c6e669-fa3d-4ff2-8343-a645a9c5cae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hagamos predicciones\n",
    "probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])\n",
    "predictions = probability_model.predict(testing_data)\n",
    "\n",
    "slice = 10\n",
    "end = slice + 30\n",
    "selected_predictions = predictions[slice:end]\n",
    "selected_actual = testing_labels[slice:end]\n",
    "\n",
    "fig, axs = plt.subplots(5, 4, figsize=(15, 20))\n",
    "\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    # Plotear el valor predicho\n",
    "    ax.bar(reversed_class_names.values(), selected_predictions[i], alpha= 0.5, label='Predicho')\n",
    "    # Plotear el valor real\n",
    "    actual_values = [0] * len(reversed_class_names)\n",
    "    actual_values[selected_actual.iloc[i]] = 1\n",
    "    ax.bar(reversed_class_names.values(), actual_values, alpha=0.5, label='Real')\n",
    "    ax.set_title(f'Predicci√≥n {i + 1}')\n",
    "    ax.set_ylabel('Confianza')\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
